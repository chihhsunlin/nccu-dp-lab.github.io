---
layout: single
title: Research
permalink: /research/
author_profile: false
---

<section class="section">
  <p style="color:#555;">
    Research at the <strong style="color:#1a73e8;">Privacy &amp; Security Lab</strong>
    focuses on the design and analysis of
    <span style="color:#1a73e8; font-weight:500;">
      privacy-preserving and secure machine learning systems
    </span>.
    Our work integrates
    <span style="font-weight:500;">differential privacy</span>,
    <span style="font-weight:500;">neural network security</span>,
    and data analysis to enable
    <span style="color:#1a73e8;">trustworthy AI</span>
    under rigorous privacy and security guarantees.
  </p>
</section>

<section class="section">
  <h2>Research Directions</h2>

  <div class="row">

    <div class="col-md-6">
      <h3 style="color:#1a73e8;">Differential Privacy Models</h3>
      <p style="color:#555;">
        We study differential privacy across
        <strong>centralized</strong>, <strong>local (LDP)</strong>, and
        <strong>shuffle models</strong>, with an emphasis on understanding
        privacy–utility trade-offs and system-level implications.
      </p>
    </div>

    <div class="col-md-6">
      <h3 style="color:#1a73e8;">Privacy Amplification &amp; Accounting</h3>
      <p style="color:#555;">
        Our research investigates
        <span style="font-weight:500;">privacy amplification</span>,
        particularly amplification via
        <span style="font-weight:500;">shuffling</span>,
        and develops accurate privacy accounting based on
        <strong>advanced composition</strong> and
        <strong>Rényi Differential Privacy (RDP)</strong>.
      </p>
    </div>

    <div class="col-md-6">
      <h3 style="color:#1a73e8;">Privacy-Preserving Data Synthesis</h3>
      <p style="color:#555;">
        We develop differentially private data synthesis techniques for
        <strong>tabular</strong>, <strong>image</strong>, and
        <strong>time-series</strong> data, enabling safe data sharing while
        preserving essential statistical properties.
      </p>
    </div>

    <div class="col-md-6">
      <h3 style="color:#1a73e8;">Neural Network Security</h3>
      <p style="color:#555;">
        We analyze security threats in learning systems, including
        <span style="font-weight:500;">data poisoning</span> and
        <span style="font-weight:500;">backdoor attacks</span>,
        and design defenses to improve model robustness.
      </p>
    </div>

    <div class="col-md-6">
      <h3 style="color:#1a73e8;">Secure &amp; Trustworthy AI Applications</h3>
      <p style="color:#555;">
        We apply privacy-preserving and secure learning techniques to
        <strong>healthcare</strong> and
        <strong>behavioral data analysis</strong>,
        aiming to build compliant and trustworthy AI systems.
      </p>
    </div>

  </div>
</section>

